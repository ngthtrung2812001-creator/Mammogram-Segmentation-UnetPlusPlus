import argparse
import os
import torch
import numpy as np
import random
import segmentation_models_pytorch as smp

# Import c√°c module v·ªá tinh (ƒê·∫£m b·∫£o b·∫°n ƒë√£ s·ª≠a c√°c file n√†y theo h∆∞·ªõng d·∫´n tr∆∞·ªõc)
from config import SEED, BASE_OUTPUT
from trainer import Trainer
from optimizer import get_optimizer # Ho·∫∑c t√™n h√†m b·∫°n ƒë√£ s·ª≠a trong optimizer.py
from dataset import get_dataloaders
from result import export, export_evaluate
from utils import get_loss_function

def get_args():
    parser = argparse.ArgumentParser(description="Train, Pretrain ho·∫∑c Evaluate model AI")
    
    # --- THAM S·ªê C∆† B·∫¢N ---
    parser.add_argument("--mode", type=str, choices=["train", "pretrain", "evaluate"], required=True, help="Ch·∫ø ƒë·ªô ch·∫°y")
    parser.add_argument("--data", type=str, required=True, help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c dataset")
    parser.add_argument("--epoch", type=int, default=50, help="S·ªë epoch ƒë·ªÉ train")
    
    # --- THAM S·ªê MODEL & TRAINING ---
    parser.add_argument("--checkpoint", type=str, help="ƒê∆∞·ªùng d·∫´n file checkpoint (cho pretrain/eval)")
    parser.add_argument("--saveas", type=str, default="default_run", help="T√™n th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£")
    parser.add_argument("--augment", action='store_true', help="B·∫≠t Augmentation (l·∫≠t, xoay, nhi·ªÖu...)")
    
    # --- HYPERPARAMETERS ---
    parser.add_argument("--lr0", type=float, default=1e-4, help="Learning rate ban ƒë·∫ßu")
    parser.add_argument("--batchsize", type=int, default=8, help="K√≠ch th∆∞·ªõc Batch size")
    parser.add_argument("--weight_decay", type=float, default=1e-4, help="Weight decay ƒë·ªÉ ch·ªëng overfitting")
    
    parser.add_argument("--img_size", type=int, nargs='+', default=[512, 512], help="K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o [H, W]")
    parser.add_argument("--numclass", type=int, default=1, help="S·ªë l·ªõp output (Binary = 1)")
    
    # --- L·ª∞A CH·ªåN LOSS & OPTIMIZER ---
    parser.add_argument("--loss", type=str, 
                        choices=["Tversky_loss", "FocalTversky_loss", "Combo_loss", "Dice_loss", "BCEw_loss", "BCEDice_loss"], 
                        default="Tversky_loss", 
                        help="H√†m loss s·ª≠ d·ª•ng")
    
    parser.add_argument("--optimizer", type=str, choices=["Adam", "SGD", "AdamW"], default="AdamW", help="Optimizer s·ª≠ d·ª•ng")
    
    args = parser.parse_args()
    
    # Ki·ªÉm tra logic b·∫Øt bu·ªôc
    if args.mode in ["pretrain", "evaluate"] and not args.checkpoint:
        parser.error(f"‚ùå B·∫°n ph·∫£i cung c·∫•p --checkpoint khi ch·∫°y ch·∫ø ƒë·ªô '{args.mode}'")
        
    return args

def set_seed():
    """Thi·∫øt l·∫≠p seed ƒë·ªÉ t√°i l·∫≠p k·∫øt qu·∫£"""
    torch.manual_seed(SEED)
    random.seed(SEED)
    np.random.seed(SEED)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(SEED)
        torch.cuda.manual_seed_all(SEED)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def main(args):  
    print(f"\n{'='*60}")
    print(f"üöÄ RUNNING MODE: {args.mode.upper()}")
    print(f"üìÇ Dataset:  {args.data}")
    print(f"üß† Model:    Unet++ (EfficientNet-B4)")
    print(f"üìâ Loss:     {args.loss}")
    print(f"‚öôÔ∏è  Img Size: {args.img_size} | Batch: {args.batchsize} | LR: {args.lr0}")
    print(f"{'='*60}\n")

    set_seed()
    
    # ====================================================
    # 1. KH·ªûI T·∫†O MODEL (Unet++ & EfficientNet-B4)
    # ====================================================
    print(f"[INFO] Initializing Model Unet++ with EfficientNet-B4...")
    model = smp.UnetPlusPlus(
        encoder_name="efficientnet-b4", # ƒê√£ ƒë·ªïi theo y√™u c·∫ßu c·ªßa b·∫°n
        encoder_weights="imagenet",     
        in_channels=3,                  # Gi·∫£ s·ª≠ b·∫°n copy k√™nh x√°m th√†nh 3 k√™nh RGB
        classes=args.numclass,          # Th∆∞·ªùng l√† 1 cho Binary Segmentation
        decoder_attention_type="scse"   # Module attention gi√∫p model t·∫≠p trung v√†o v√πng u
    )

    # ====================================================
    # 2. KH·ªûI T·∫†O OPTIMIZER
    # ====================================================
    # L∆∞u √Ω: C·∫ßn ƒë·∫£m b·∫£o file optimizer.py c√≥ h√†m nh·∫≠n c√°c tham s·ªë n√†y
    optimizer = get_optimizer(
        model=model
        # N·∫øu h√†m optimizer c·ªßa b·∫°n ƒë√£ s·ª≠a ƒë·ªÉ nh·∫≠n lr/weight_decay th√¨ b·ªè comment d√≤ng d∆∞·ªõi:
         , lr=args.lr0, weight_decay=args.weight_decay, opt_name=args.optimizer
    ) 
    # N·∫øu ch∆∞a s·ª≠a optimizer.py, n√≥ s·∫Ω d√πng m·∫∑c ƒë·ªãnh trong config (kh√¥ng khuy·∫øn kh√≠ch)

    # ====================================================
    # 3. KH·ªûI T·∫†O LOSS FUNCTION
    # ====================================================
    criterion = get_loss_function(args.loss)

    # ====================================================
    # 4. KH·ªûI T·∫†O TRAINER
    # ====================================================
    trainer = Trainer(
        model=model, 
        optimizer=optimizer,
        criterion=criterion,
        num_epochs=args.epoch,
        patience=20 # B·∫°n c√≥ th·ªÉ th√™m tham s·ªë n√†y v√†o args n·∫øu mu·ªën ch·ªânh
    )

    # ====================================================
    # 5. LOAD D·ªÆ LI·ªÜU (DATALOADERS)
    # ====================================================
    # ƒê·∫£m b·∫£o dataset.py/get_dataloaders ƒë√£ s·ª≠a ƒë·ªÉ nh·∫≠n tham s·ªë
    trainLoader, validLoader, testLoader = get_dataloaders(
        data_dir=args.data,      
        batch_size=args.batchsize,
        img_size=args.img_size,  
        augment=args.augment
    )

    # ====================================================
    # 6. TH·ª∞C THI (TRAIN / PRETRAIN / EVALUATE)
    # ====================================================
    
    # --- CASE 1: TRAIN M·ªöI T·ª™ ƒê·∫¶U ---
    if args.mode == "train":
        print("[INFO] Start Training from scratch...")
        trainer.train(trainLoader, validLoader, resume_path=None)
        # L∆∞u k·∫øt qu·∫£ v√†o th∆∞ m·ª•c ƒë·ªãnh s·∫µn
        export(trainer, save_dir=args.saveas)

    # --- CASE 2: TRAIN TI·∫æP (PRETRAIN) ---
    elif args.mode == "pretrain":
        print(f"[INFO] Start Pre-training (Resume from {args.checkpoint})...")
        trainer.train(trainLoader, validLoader, resume_path=args.checkpoint)
        export(trainer, save_dir=args.saveas)

    # --- CASE 3: ƒê√ÅNH GI√Å (EVALUATE) ---
    elif args.mode == "evaluate":
        print(f"[INFO] Start Evaluating...")
        
        # T·∫°o ƒë∆∞·ªùng d·∫´n l∆∞u ·∫£nh visual
        visual_folder = os.path.join(BASE_OUTPUT, args.saveas, "prediction_images")
        
        # Ch·∫°y evaluate tr√™n t·∫≠p TEST (kh√¥ng ph·∫£i valid)
        trainer.evaluate(
            test_loader=testLoader, 
            checkpoint_path=args.checkpoint,
            save_visuals=True,          
            output_dir=visual_folder    
        )
        
        # Xu·∫•t file CSV chi ti·∫øt
        export_evaluate(trainer, save_dir=args.saveas)

if __name__ == "__main__":
    args = get_args()
    main(args)