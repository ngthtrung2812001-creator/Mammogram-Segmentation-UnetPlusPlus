#!/bin/bash

# ==============================================================================
# üöÄ GRAND MASTER PIPELINE RUNNER
# ==============================================================================

# 1. C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N D·ªÆ LI·ªÜU
# Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y tr·ªè ƒë·∫øn th∆∞ m·ª•c "Final_Dataset_Patches" b·∫°n ƒë√£ t·∫°o
DATA_PATH="/mnt/d/cbis_ddsm_512_lanczos/Patches"

# T√™n th∆∞ m·ª•c s·∫Ω l∆∞u k·∫øt qu·∫£ (trong folder output/z)
RUN_NAME="GrandMaster_EffB5_GammaV1"

# ==============================================================================
# PH·∫¶N 1: HU·∫§N LUY·ªÜN M·ªöI (TRAINING FROM SCRATCH)
# Ch·∫°y d√≤ng n√†y ƒë·ªÉ b·∫Øt ƒë·∫ßu train model.
# ==============================================================================

# echo "üî• [START] B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh Grand Master..."

# python train.py \
#   --mode train \
#   --data "$DATA_PATH" \
#   --saveas "$RUN_NAME" \
#   --backbone "efficientnet-b5" \
#   --epoch 50 \
#   --batchsize 4 \
#   --lr0 1e-4 \
#   --loss FocalTversky_loss \
#   --optimizer AdamW \
#   --augment \
#   --img_size 512 512

# Gi·∫£i th√≠ch tham s·ªë:
# --backbone "efficientnet-b5": D√πng m·∫°ng n∆°-ron s√¢u v√† m·∫°nh m·∫Ω.
# --batchsize 4: An to√†n cho GPU 8GB-12GB VRAM (V√¨ B5 r·∫•t n·∫∑ng).
# --loss FocalTversky_loss: T·ªëi ∆∞u cho d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng (U nh·ªè).
# --augment: B·∫≠t ch·∫ø ƒë·ªô l√†m m√©o ·∫£nh (Elastic Transform) ƒë·ªÉ ch·ªëng overfitting.

# ==============================================================================
# PH·∫¶N 2: TI·∫æP T·ª§C HU·∫§N LUY·ªÜN (RESUME / PRETRAIN)
# D√πng khi b·ªã m·∫•t ƒëi·ªán ho·∫∑c mu·ªën train th√™m epoch cho model c≈©.
# (B·ªè comment d√≤ng d∆∞·ªõi ƒë·ªÉ ch·∫°y)
# ==============================================================================

# echo "üîÑ [RESUME] Ti·∫øp t·ª•c hu·∫•n luy·ªán t·ª´ checkpoint..."

# python train.py \
#   --mode pretrain \
#   --data "$DATA_PATH" \
#   --saveas "${RUN_NAME}_Resume" \
#   --checkpoint "output/$RUN_NAME/last_model.pth" \
#   --backbone "efficientnet-b5" \
#   --epoch 50 \
#   --batchsize 4 \
#   --lr0 1e-5 \
#   --loss FocalTversky_loss \
#   --augment

# ==============================================================================
# PH·∫¶N 3: KI·ªÇM NGHI·ªÜM & ƒê√ÅNH GI√Å (EVALUATE / TESTING)
# Ch·∫°y d√≤ng n√†y SAU KHI train xong ƒë·ªÉ t√≠nh ƒëi·ªÉm Dice/IoU tr√™n t·∫≠p Test
# v√† xu·∫•t ·∫£nh d·ª± ƒëo√°n ra ƒë·ªÉ m·∫Øt th∆∞·ªùng ki·ªÉm tra.
# ==============================================================================

echo "üìä [EVAL] ƒêang ƒë√°nh gi√° model t·ªët nh·∫•t tr√™n t·∫≠p Test..."

# python train.py \
#   --mode evaluate \
#   --data "$DATA_PATH" \
#   --saveas "$RUN_NAME" \
#   --checkpoint "output/$RUN_NAME/best_dice_mass_model.pth" \
#   --backbone "efficientnet-b5" \
#   --batchsize 8 \
#   --img_size 512 512

#Full image evaluation
python train.py \
  --mode evaluate \
  --data "$DATA_PATH" \
  --saveas "GrandMaster_FullEval" \
  --checkpoint "output/GrandMaster_EffB5_GammaV1/best_dice_mass_model.pth" \
  --backbone "efficientnet-b5" \
  --full_eval

# L∆∞u √Ω:
# --checkpoint: Tr·ªè v√†o file model c√≥ Dice Score cao nh·∫•t (best_dice_mass_model.pth)
# --batchsize 8: L√∫c test kh√¥ng c·∫ßn t√≠nh ƒë·∫°o h√†m n√™n c√≥ th·ªÉ tƒÉng batchsize ƒë·ªÉ ch·∫°y nhanh h∆°n.

echo "‚úÖ [DONE] Ho√†n t·∫•t quy tr√¨nh!"